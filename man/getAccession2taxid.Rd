% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/taxa.R
\name{getAccession2taxid}
\alias{getAccession2taxid}
\title{Download accession2taxid files from NCBI}
\usage{
getAccession2taxid(
  outDir = ".",
  baseUrl = sprintf("\%s://ftp.ncbi.nih.gov/pub/taxonomy/accession2taxid/", protocol),
  types = c("nucl_gb", "nucl_wgs"),
  protocol = "ftp",
  resume = TRUE
)
}
\arguments{
\item{outDir}{the directory to put the accession2taxid.gz files in}

\item{baseUrl}{the url of the directory where accession2taxid.gz files are located}

\item{types}{the types if accession2taxid.gz files desired where type is the prefix of xxx.accession2taxid.gz. The default is to download all nucl_ accessions. For protein accessions, try \code{types=c('prot')}.}

\item{protocol}{the protocol to be used for downloading. Probably either \code{'http'} or \code{'ftp'}. Overridden if \code{baseUrl} is provided directly}

\item{resume}{if TRUE attempt to resume downloading an interrupted file without starting over from the beginning}
}
\value{
a vector of file path strings of the locations of the output files
}
\description{
Download a nucl_xxx.accession2taxid.gz from NCBI servers. These can then be used to create a SQLite datanase with \code{\link{read.accession2taxid}}. Note that if the files already exist in the target directory then this function will not redownload them. Delete the files if a fresh download is desired.
}
\examples{
\dontrun{
  if(readline(
    "This will download a lot data and take a while to process.
     Make sure you have space and bandwidth. Type y to continue: "
  )!='y')
    stop('This is a stop to make sure no one downloads a bunch of data unintentionally')

  getAccession2taxid()
}
}
\references{
\url{https://ftp.ncbi.nih.gov/pub/taxonomy/}, \url{https://www.ncbi.nlm.nih.gov/genbank/acc_prefix/}
}
\seealso{
\code{\link{read.accession2taxid}}
}
